---
title: "【馬券戦略編①】期待値計算と確率キャリブレーション：スコアを「勝率」に変える"
emoji: "💰"
type: "tech"
topics: ["python", "機械学習", "確率", "数理最適化", "データ分析"]
published: false
---

# 【馬券戦略編①】期待値計算と確率キャリブレーション：スコアを「勝率」に変える

## はじめに：AIのスコアは「確率」ではない

ランク学習モデル（`LGBMRanker`）が出力するのは、あくまで「強さの順序を表すスコア」です。
このスコアは「3.5」や「-1.2」といった任意の実数値であり、そのままでは「勝率」として扱えません。

馬券で勝つための鉄則は**「期待値（Expected Value）の高い馬を買う」**ことです。
期待値を計算するには、正確な「勝率（確率）」が不可欠です。

$$ 期待値 = 勝率 \times オッズ $$

今回は、AIのスコアを信頼できる「勝率」に変換するための技術、**Softmax関数**と**温度パラメータ（Temperature）**について解説します。

## 1. Softmax関数による確率変換

ランク学習のスコアを確率に変換するために、**Plackett-Luceモデル**に基づいたSoftmax関数を採用しました。
これは、レースに出走する全馬のスコアを、合計が1（100%）になるように正規化する手法です。

ある馬 $i$ のスコアを $s_i$ とすると、その馬が勝つ確率 $P_i$ は以下の式で表されます。

$$ P_i = \frac{\exp(s_i / T)}{\sum_{j \in Race} \exp(s_j / T)} $$

ここで重要なのが、数式内の $T$ 、すなわち**温度パラメータ（Temperature）**です。

## 2. 温度パラメータ（Temperature）の魔法

温度パラメータ $T$ は、AIの「自信の度合い」を調整する役割を持ちます。

- **$T$ が大きい場合（高温）**: 確率分布が平坦になり、どの馬も「そこそこ勝つ」という予測になります（慎重）。
- **$T$ が小さい場合（低温）**: スコアが高い馬の確率が極端に高くなり、「この馬が絶対勝つ」という予測になります（過信）。

### 最適な温度を見つける実験

`notebooks/34_score_distribution_analysis.ipynb` で、過去のデータを使って最適な $T$ を探す実験を行いました。
評価指標には、確率の正確さを測る **Log Loss（対数損失）** を使用しました。

実験の結果、以下のことが分かりました。

- $T=1.0$（標準）では、AIは少し「弱気」すぎる（1着馬の確率を低く見積もりすぎている）。
- $T$ を下げていくと精度が向上し、**$T=0.8$** の時に Log Loss が最小（最良）となった。
- $T$ を下げすぎると（0.5以下）、過信しすぎて外した時のペナルティが大きくなる。

この結果から、本番運用では **$T=0.8$** を採用しています。これにより、AIの予測を少し「尖らせる」ことで、より現実に即した勝率を算出できるようになりました。

## 3. 期待値（EV）による投資判断

確率が求まれば、あとはオッズと掛け合わせるだけで**期待値（EV）**が計算できます。

`notebooks/36_betting_ranking_strategy_simulation.ipynb` でのシミュレーション例を見てみましょう。

| 馬番 | AIスコア | 勝率 (T=0.8) | 単勝オッズ | 期待値 (EV) | 判断 |
| :--- | :--- | :--- | :--- | :--- | :--- |
| 1 | 2.5 | 45.0% | 1.8倍 | 0.81 | 見送り (トリガミ) |
| 2 | 1.8 | 20.0% | 6.5倍 | **1.30** | **買い！** |
| 3 | -0.5 | 1.5% | 100.0倍 | 1.50 | 買い？ (確率は低い) |

AIが「本命」と判断した馬番1でも、オッズが低すぎれば期待値は1を下回り、長期的には損をします。
逆に、AI評価が2番手の馬番2は、オッズとのバランスが良く、期待値が1を超えています。

このように、**「当てること」ではなく「儲けること」**を目的に、期待値を基準にして購入馬を選定します。

## 4. 実装コード

このロジックは `ranking_prediction_service.py` ではなく、分析フェーズや馬券購入ロジック内で実装されています。

```python
# 確率変換のイメージ
import numpy as np

def calculate_prob(scores, temperature=0.8):
    exp_scores = np.exp(scores / temperature)
    return exp_scores / np.sum(exp_scores)

# 期待値計算のイメージ
df['prob'] = df.groupby('race_id')['pred_score'].transform(calculate_prob)
df['expected_value'] = df['prob'] * df['odds']
```

## まとめ

- ランク学習のスコアは、Softmax関数で確率に変換する。
- 温度パラメータ $T=0.8$ を適用することで、確率の精度（Log Loss）を最適化した。
- 最終的な購入判断は、予測確率ではなく「期待値（EV）」に基づいて行う。

しかし、「期待値が1.01以上なら全部買う」という単純な戦略では、確率のブレ（分散）に耐えられず破産するリスクがあります。

次回は、**Optuna** を用いて、「期待値いくら以上で買うべきか？」「確率は最低何%必要か？」といった**購入ルールの最適化**を行うプロセスについて解説します。