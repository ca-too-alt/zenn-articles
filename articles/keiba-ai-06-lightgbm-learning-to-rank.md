---
title: "【モデル編①】アルゴリズム選定：なぜランク学習に行き着いたか"
emoji: "📊"
type: "tech"
topics: ["python", "機械学習", "lightgbm", "ランク学習", "データ分析"]
published: false
---

# 【モデル編①】アルゴリズム選定：なぜランク学習に行き着いたか

## はじめに：AIに「何を」予測させるか？

特徴量の準備が整い、いよいよAIモデルの設計に入ります。
ここで最も重要な問いは「AIに何を予測させるか？」です。

- 1着になる馬を当てる「分類問題」？
- 各馬の走破タイムを予測する「回帰問題」？

どちらも試しましたが、より競馬の本質に近い予測を行うため、最終的に **「ランク学習（Learning to Rank）」**というアプローチに行き着きました。

今回は、なぜDeep LearningではなくLightGBMを選んだのか、そしてなぜ単純な予測問題からランク学習へ移行したのか、その思考プロセスを解説します。

## 1. なぜDeep Learningではないのか？

AIというとDeep Learning（深層学習）を想像する方が多いかもしれません。しかし、競馬の予測で扱うような「馬柱」に似た**テーブルデータ**（表形式のデータ）においては、**LightGBM**に代表される勾配ブースティング決定木（GBDT）の方が高い性能を発揮することが多いと言われています。

理由は以下の通りです。

- **特徴量の交互作用に強い**: 「この騎手は、雨の中山1200mだと特に強い」といった、複数の条件が組み合わさったパターンを自動で発見するのが得意です。
- **学習が高速**: Deep Learningに比べて計算コストが低く、試行錯誤のサイクルを速く回せます。
- **解釈性が高い**: `feature_importance`（特徴量の重要度）を算出できるため、「AIが何を根拠に予測したのか」を分析しやすいです。

これらの理由から、本プロジェクトではベースとなるアルゴリズムとしてLightGBMを採用しました。

## 2. 「1頭ずつ評価する」アプローチの限界

最初に試したのは、各馬の「走破タイム」を予測する回帰モデル（`LGBMRegressor`）でした。
しかし、このアプローチには大きな問題がありました。

**「レースごとのメンバーレベルを考慮できない」**

例えば、AIがある馬の予測タイムを「90.5秒」と弾き出したとします。このタイムの価値は、レースのメンバーによって全く異なります。

- **G1レース**なら、平凡かそれ以下のタイムかもしれません。
- **未勝利戦**なら、圧勝レベルのタイムかもしれません。

モデルは1頭ずつバラバラに評価するため、その馬がレース内で相対的にどのくらい強いのかを判断できません。
「1着と2着のタイム差」と「17着と18着のタイム差」を同じ「誤差」として扱ってしまう点も、馬券購入の観点からは不都合でした。

## 3. ランク学習：レース全体を「順序付け」する

この問題を解決するのが**ランク学習（Learning to Rank）**です。

ランク学習は、個々の馬の絶対的なタイムを予測するのではなく、**「あるレース内での、正しい順序」**そのものを学習します。

### LightGBMにおけるランク学習

LightGBMには、ランク学習専用の `LGBMRanker` というモデルがあります。
このモデルの最大の特徴は、学習時に `group` という情報を与える点です。

`ranking_training_service.py` の学習部分を見てみましょう。

```python
# c:\keiba_app\src\keiba\services\analysis\application\ranking_training_service.py

# race_idでソートされている前提
train_groups = df[df['race_id'].isin(train_races)].groupby('race_id', sort=False).size().to_numpy()
# -> array([18, 16, 18, 15, ...])

valid_groups = df[df['race_id'].isin(valid_races)].groupby('race_id', sort=False).size().to_numpy()

lgb_ranker.fit(
    X_train, y_train, group=train_groups,
    eval_set=[(X_valid, y_valid)], eval_group=[valid_groups],
    ...
)
```

`group=[18, 16, 18, ...]` という配列は、「最初の18頭は同じレース」「次の16頭は別の同じレース」というように、データの区切りをモデルに教えています。

これにより、`LGBMRanker`はレース単位で評価を行い、「この18頭のリストの中で、どの馬が最も上位に来るべきか」という**相対的な順序関係**を最適化しようとします。

### 正解ラベル（relevance）の工夫

ランク学習では、正解ラベルとして「関連度（relevance）」を与えます。今回は、着順が低い（1着に近い）ほど高いスコアになるように変換しています。

```python
# c:\keiba_app\src\keiba\services\analysis\application\ranking_training_service.py

# 18頭立ての場合: 1着 -> 18点, 2着 -> 17点, ..., 18着 -> 1点
df['relevance'] = df.groupby('race_id')['rank'].transform(lambda x: x.max() - x + 1)
```

## まとめ

「1頭ずつの絶対評価」から「レース単位での相対評価」へ。
この発想の転換を可能にしたのが、LightGBMのランク学習機能でした。

これにより、単に速い馬を見つけるだけでなく、レースの文脈の中で「勝ち切る馬」「上位に来る馬」をより正確に順序付けすることが可能になりました。

しかし、全てのレースを単一のランク学習モデルで予測するには限界があります。競馬には「展開」「ペース」といった複雑な要素が絡み合うからです。

次回は、このランク学習モデルをさらに進化させ、競馬のプロセスを模倣した **「3モデル連携アーキテクチャ」**について解説します。