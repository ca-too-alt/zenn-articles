---
title: "【加工編】未来の情報を漏らすな：特徴量エンジニアリングと「指紋ファイル」"
emoji: "🧪"
type: "tech"
topics: ["python", "機械学習", "featureengineering", "データリーク", "pandas"]
published: false
---

# 【加工編】未来の情報を漏らすな：特徴量エンジニアリングと「指紋ファイル」

## はじめに：データリークという落とし穴

機械学習モデルの構築において、最も注意すべき問題の一つが **「データリーク（リーク）」**です。
これは、予測時点では知り得ない「未来の情報（答え）」が、学習データの中に誤って混入してしまう現象を指します。

例えば、レース結果（着順や走破タイム）や、レース確定後に判明するオッズなどが特徴量に含まれていると、モデルはそれらをカンニングして学習してしまいます。その結果、学習時には極めて高い精度が出るものの、実運用では全く使い物にならないモデルが出来上がります。

今回は、このリークを防ぐための工夫と、学習したモデルを安全に運用するための仕組みについて解説します。

## 1. 指紋ファイルシステム：列のズレを防ぐ

### ハードコードの限界と「列のズレ」
最初は、学習に使う列名をコードの中に直接書いて（ハードコードして）管理していました。
しかし、開発が進むにつれて「あれ、このモデルにはこの列入れたっけ？」と混乱し、学習時と予測時で列が一致しないエラーが頻発しました。

さらに追い打ちをかけたのが **One-Hot Encoding**（カテゴリ変数のダミー変数化）です。
例えば「天気」という項目があり、学習データには「晴れ、曇り、雨」があったので3列作られます。
しかし、予想したい日のデータに「雨」がなければ、2列しか作られません。

```
ValueError: Number of features of the model must match the input.
Model n_features is 100 and input n_features is 98
```

これで列数が合わなくなり、AIが動かなくなります。

### 解決策：データの「指紋」をとる

そこで導入したのが、学習時のデータの形を記録しておく **「指紋ファイルシステム」**です。

学習が完了した瞬間、以下の2つのファイルを保存します。

- **`columns.txt`**: 列の並び順リスト（指紋）
- **`dtypes.txt`**: 各列のデータ型

予測時には、この「指紋」をロードし、入力データを強制的に整形します。

1.  **足りない列があれば、0で埋めて追加する。**
2.  **余計な列があれば、削除する。**
3.  **列の並び順を、指紋通りに並べ替える。**

これにより、どんなデータが来ても、AIが期待する形にピタリと合わせることができるようになりました。

## 2. データリーク：未来情報の排除

### タイムマシンはいらない
競馬予想において、「走破タイム」や「着順」は未来の情報です。
これらを学習に使ってしまうと、AIは答えをカンニングしてしまいます。これが典型的なデータリークです。

### オッズをあえて使わない理由
一方で、オッズはレース前に取得できるので未来情報ではありません。
しかし、今回のAIでは**あえてオッズを学習データから除外**しています。

オッズを学習させると、AIは「オッズが低い（人気がある）馬は強い」という法則に過剰に依存してしまい、オッズ通りの予想しかしなくなります。
目指すのは **「世間の評価（オッズ）よりも実力がある穴馬」**を見つけることです。
そのため、オッズは予測モデルには入れず、最後の「期待値計算」で初めて使用します。

### 過去の平均値の罠
「過去の平均順位」という特徴量を作るとき、単純に `mean()` を計算すると、**「今回のレース結果」も平均に含まれてしまいます。**

これを防ぐために、特徴量生成`feature_generator.py` では `shift(1)` という操作を徹底しています。

```python
# 1. まず時系列順に並べる
df = df.sort_values('date')

# 2. グループごとに集計するが...
grouped = df.groupby('horse_id')['rank']

# 3. shift(1) で「1つ前」までのデータを参照するようにずらす
df['avg_rank'] = grouped.expanding().mean().shift(1)
```

これにより、常に「前走までのデータ」だけを使って特徴量が計算されるようになります。

### 設定ファイルによる厳格な管理
さらに、`src/keiba/config/columns.py` という設定ファイルで、学習に使ってはいけない列（`DROP_COLS`）を定義し、プログラム的に強制排除しています。

```python
# モデル学習時に必ず削除するカラム
DROP_COLS = [
    'rank',          # 着順（答え：リーク）
    'finish_time',   # 走破タイム（答え：リーク）
    'odds_win',      # 単勝オッズ（過学習防止のため除外）
    ...
]
```

## 3. 相対評価：絶対値の嘘

「タイム：1分33秒」という数字には、実はあまり意味がありません。
競馬場の芝の状態や天候によって、タイムは大きく変わるからです。

重要なのは「そのレースの中で、他の馬より速かったか？」です。

そこで、数値をそのまま使うのではなく、レース内での **「偏差」**や **「スケーリング（0〜1）」**に変換してAIに渡しています。

```python
# レースごとの最大値・最小値を使って 0.0〜1.0 に変換
def apply_position_scaling(df):
    # ... (レースごとの処理)
    score = (x - min_s) / (max_s - min_s)
    return score
```

これにより、AIは「今日は全体的に時計がかかる日だ」といったノイズに惑わされず、純粋な能力差を比較できるようになりました。

## まとめ

データ加工は、AIに「正しく、公平な」問題を解かせるための試験作成のようなものです。

指紋ファイルで形式を整え、リークを排除し、相対評価で本質を浮き彫りにする。
ここまで準備して初めて、まともな学習が可能になります。

次回は、AIがレースをどう見ているのか、具体的な「特徴量」の中身について解説します。