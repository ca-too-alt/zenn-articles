---
title: "【収集編】Playwright vs オッズAPI：動的コンテンツとの戦い"
emoji: "🕷️"
type: "tech"
topics: ["python", "playwright", "スクレイピング", "fastapi", "データ収集"]
published: false
---

# 【収集編】Playwright vs オッズAPI：動的コンテンツとの戦い

## はじめに：HTMLの中にデータがない？

「設計」と「環境」が整い、いよいよデータ収集のコードを書き始めました。（AIが）
過去のレース結果（着順やタイム）は、Pythonの定番ライブラリ `BeautifulSoup` と `httpx` を使って、HTMLから簡単に取得できました。

「なんだ、楽勝じゃん」

そう思ったのも束の間、「オッズデータ」の取得で壁にぶつかりました。
ブラウザで見ると確かに数字が表示されているのに、スクレイピングしたHTMLの中には**オッズの数字がどこにもない**のです。

## 1. 動的コンテンツの壁

最近のWebサイトは、ページを開いた後にJavaScriptが裏で通信を行い、データを取ってきて画面を書き換える「動的コンテンツ」になっていることがあります。

`BeautifulSoup` は「最初のHTML」しか見ないため、JavaScriptが動く前の空っぽの状態しか取得できません。
これに対抗するには、**「ブラウザそのものをプログラムで操作する」**必要があります。

## 2. Playwright：ブラウザ自動化ツール

Playwrightには以下の特徴があります。

- **高速:** 非同期処理（`async/await`）に完全対応しており、FastAPIとの相性が良い。
- **強力な待機機能:** 「特定の通信が完了するまで待つ」といった制御が簡単に書ける。
- **ネットワーク傍受:** これが最大の決め手です。

### 画面を解析するな、通信を盗み見ろ

最初は「画面に表示された数字」を読み取ろうとしていました。しかし、オッズ画面は複雑で、HTMLの構造が変わるとすぐに動かなくなります。

ここで発想を転換しました。
**「ブラウザが裏で叩いているAPIのレスポンスを、横から盗み見ればいいのでは？」**

Playwrightには `expect_response` という機能があります。これを使って、オッズデータが含まれる「内部API」の通信を捕まえることに成功しました。

実際のコード（`odds_scraper.py`）の核心部分です：

```python
# オッズページに遷移しつつ、裏で走るAPIリクエストを待ち構える
async with self.page.expect_response(
    lambda res: "api/api_get_odds.html" in res.url and "action=init" in res.url,
    timeout=60000,
) as response_info:
    # ブラウザでページを開く
    await self.page.goto(odds_page_url, wait_until="domcontentloaded")

# 捕まえたレスポンスから中身（JSONデータ）を取り出す
initial_response = await response_info.value
```

これにより、画面の描画を待つ必要すらなく、生のデータを直接手に入れることができるようになりました。

## 3. 過去データの「馬番」トラップ

データは取れましたが、保存する段階で恐ろしいバグに遭遇しました。

**「1番人気のオッズが、常に1番の馬（馬番1）に記録されている…？」**

APIから返ってくるJSONデータを確認すると、キーが「馬番」ではなく「人気順」になっていたのです。

```json
// APIレスポンスのイメージ（実際はもっと複雑）
"odds": {
    "1": ["2.5", ...],  // これが「馬番1」ではなく「1番人気」のデータだった！
    "2": ["4.8", ...],
    ...
}
```

何も考えずにループで保存すると、「1番人気の馬のオッズ」が「馬番1の馬」としてDBに保存されてしまいます。
これに気づかずに学習させていたら、**「常に1番の馬が強い」と勘違いするポンコツAI**が爆誕するところでした。

### 解決策

データをよく観察すると、リストの中にこっそりと「馬番」の情報が含まれていました。

```python
# valueは ['オッズ', '更新時間', '人気', '馬番文字列'] のリスト形式
# 例: ["4.6", null, 1, "0810"]
```

そこで、キー（連番）は信用せず、値の中にある「馬番文字列」をパースして、正しい馬番と紐付けるロジックを実装しました。

```python
# 馬番文字列を取得 (index=3)
raw_horse_str = str(value[3])

# "0810" -> [8, 10] (馬連8-10) のように変換
horse_numbers = [int(raw_horse_str[i:i+2]) for i in range(0, len(raw_horse_str), 2)]
```

この修正により、過去数年分のオッズデータを正しくデータベースに格納することができました。

## まとめ：データ収集は「泥臭い」

華やかなAI開発の裏側には、こうした地味で泥臭いデータ収集の苦労があります。
ここをサボると、どんなに高性能なAIモデルを使ってもゴミしか生まれません。

Playwrightによる「API傍受」と、執念の「データ構造解析」。
この2つによって、AIの燃料となるオッズデータを確保することができました。

次回は、集めたデータをAIが学習できる形に変換する「加工編」です。